<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Technological Mediation</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr. Ryan Straight" />
    <script src="index_files/header-attrs/header-attrs.js"></script>
    <link href="index_files/remark-css/default.css" rel="stylesheet" />
    <script src="index_files/fabric/fabric.min.js"></script>
    <link href="index_files/xaringanExtra-scribble/scribble.css" rel="stylesheet" />
    <script src="index_files/xaringanExtra-scribble/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#FF0000"],"pen_size":3,"eraser_size":30}) })</script>
    <link href="index_files/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <script src="index_files/clipboard/clipboard.min.js"></script>
    <link href="index_files/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="index_files/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"<i class=\"fa fa-clipboard\"><\/i>","success":"<i class=\"fa fa-check\" style=\"color: #90BE6D\"><\/i>","error":"<i class=\"fa fa-times-circle\" style=\"color: #F94144\"><\/i>"})</script>
    <link href="index_files/font-awesome/css/all.css" rel="stylesheet" />
    <link href="index_files/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <script type="application/json" id="xaringanExtra-editable-docid">{"id":"f549bc2a212545c189f70f55b7d46135","expires":1}</script>
    <script src="index_files/himalaya/himalaya.js"></script>
    <script src="index_files/js-cookie/js.cookie.js"></script>
    <link href="index_files/editable/editable.css" rel="stylesheet" />
    <script src="index_files/editable/editable.js"></script>
    <link rel="stylesheet" href="assets/arizona-fonts.css" type="text/css" />
    <link rel="stylesheet" href="assets/arizona.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Technological Mediation
## A Postphenomenology Primer for Instructors, Designers, and More
### Dr. Ryan Straight
### 2021 September 21

---





# Today's schedule

.pull-left[

+ Intros
+ What is postphenomenology?
+ Why is it relevant to us?
+ How do you *do* it?

## Questions during?

## Ask away!

]

.pull-right[

&lt;div style="width:100%;height:0;padding-bottom:100%;position:relative;"&gt;&lt;iframe src="https://giphy.com/embed/ZbOXZEugwT26awakGe" width="100%" height="100%" style="position:absolute" frameBorder="0" class="giphy-embed" allowFullScreen&gt;&lt;/iframe&gt;&lt;/div&gt;&lt;p&gt;&lt;a href="https://giphy.com/gifs/latenightseth-lol-seth-meyers-lnsm-ZbOXZEugwT26awakGe"&gt;via GIPHY&lt;/a&gt;&lt;/p&gt;

]

???

Welcome! I applaud you for joining the session, especially if you've never heard of postphenomenology since it's not exactly the most welcoming word (in fact, the scholar who coined it wishes he'd picked something else). If you think of yourself as a bit of a tech nerd, you are so in the right place.

The plan for today is as such. A bit about me and why I've got you here, what this whole concept is, why it's relevant to us, and then... how you actually quote-unquote "do" it. Because postphenomenology is both a framework for understanding how people, technology, and the world co-create our perceptions but also a methodology for how to empirically examine that relationship and experience.

To be honest, you may recognize some of the concepts we're talking about today. You may know them or versions of them as different terminology in other frameworks and methodologies. And that's okay! That's really what today is going to be about: providing you with another toolbox with some tools that are brand new, and some old tools that you'll be looking at in--hopefully--a new way.

Of course, if you have questions or comments during the session, please don't hesitate to put them in the chat or raise your hand. Perhaps I can answer them, and if I can I will, but my goal here is not to provide a step-by-step on how to do this particular thing, but rather to get you, this community, to ask questions. So, on with the show!

---
class: secondary-silver
background-image: url("assets/ua_horiz_rgb_black_4.svg")
background-size: 20%
background-position: 95% 95%

# Introductions

(icon)

---

# Dr Ryan Straight

(slide about me)

---
class: secondary-river
background-image: url("assets/ua_horiz_rgb_4.svg")
background-size: 20%
background-position: 95% 95%

# What is postphenomenology?

???

I'll be giving a brief overview of what PP is and where it comes from, but the majority of the work in terms of "doing" PP and its integration into this education space actually comes from the work of Catherine Adams and others. So, using her definition, postphenomenology is:


--

"[a] phenomenology that attends to specific technologies and the existential and epistemological differences they may be making to the lifeworld" (Adams &amp; Turville, 2018, p.4).

???

&gt;"phenomenology that attends to specific technologies and the existential and epistemological differences they may be making to the lifeworld" (Adams &amp; Turville, 2018, p.4).

And we'll unpack that as this session goes on and you'll have access to a collection of references and resources involved in this topic. But first, how did we get from traditionally phenomenology to ... this?

---
class: brand-blue

# A **brief** history of postphenomenology

.pull-left[


]


.pull-right[

## The necker cube: variational analysis

![](https://upload.wikimedia.org/wikipedia/commons/e/e7/Necker_cube.svg)&lt;!-- --&gt;

.font40[Source: Wiki Commons: https://commons.wikimedia.org/wiki/File:Necker_cube.svg]

]
...

???

This is going to be very brief because I'm going to dig into most of this more throughout the session, so if something doesn't quite make sense yet, just hang on.

+ First, phenomenology. And when I say "brief," I mean *super* brief. 
    + Essentially, if you recall from your days taking philosophy 101, phenomenology is a framework for understanding consciousness and our place in the world by understanding that consciousness is always *directed* or *intentional*. The old "you can't think of nothing" idea. In order to quote-unquote "do" phenomenology, the researcher must remove all prejudice and intefering preconceptions about the thing they're studying to focus on, as Husserl puts it, "The things themselves."
+ Ihde
    + Then Don Ihde comes along and says, "Hang on, this whole phenomenology thing should make this a bit more pragmatic. Now we have all this technology that doesn't *intefere* with how we see and experience the world, it actually *mediates* that experience! And we should study that, not put it aside!"
    + So he comes up with a new, call it "modern" version of phenomenology, and appends "post" to it, not to say it's the successor, but to point out that it's acknowledging the 20th century "empirical turn."
    + He writes a text called *Technology and the Lifeworld*, in which he outlines the basic tenets of the new postphenomenological framework. It's not perfect but it gets the conversation started.
+ Verbeek and others
    + Scholars begin studying under Ihde and coming up with their own improvements on and variations of the framework. Verbeek, for example, begins focusing on a theory of technological mediation specifically, while others begin incorporating it into their own fields of interest like the study of medical assistive devices or, again in Verbeek's case, studying a la Husserl, "things, themselves" like park benches.
+ Actor Network Theory
    + Related to postphenomenology is Actor Network Theory, typically attributed to Bruno Latour, which focuses on objectivity and subjectivity being co-constructed by the "actors" within a "network." So, a person and a chair aren't subjects or objects until they interact, at which point their positionality is established. Essentially. These networks can and do shift, so ANT is a framework and methodology for examining this. I mention it here because it's related to postphenomenology in that the latter informs the former with the ability to examine things, as Verbeek puts it, "from inside out."
+ That brings us to applied postphenomnology, or Adams' "postphenomenology of practice," as her specific version is based on the phenomenological work of Van Manen, whom she studied under.
    + I *highly* encourage you read the work I link in the resources and references if this is piquing your interest. It's really fascinating. Adams' work, especially. This is how we're quote-unquote "doing" postphenomenology in our particular case. And we'll come back to that.
  

---
class: secondary-silver
background-image: url("assets/ua_horiz_rgb_black_4.svg")
background-size: 20%
background-position: 95% 95%

# Terminology

???

So we've got our basic background of this framework but let's dig into the specific terminology a bit more before we start talking about how we can use it. Listen closely as there will be a quiz. :D


---
class: brand-red

## Technological mediation

&gt; Technology *necessarily* mediates our experience with the world.

???

When we think of how we interact with the world, in classical phenomenology, as I briefly mentioned just a minute ago, we're encouraged (required, in fact) to "block" or otherwise attempt to eschew all elements of the lifeworld that can interfere with our experience to get to the root of the thing. PP says, no, technology (as we experience it now) shouldn't be dismissed or considered a hindrance but rather something to be empirically studied. And we'll look at just how postphenomenologists like Ihde typically envision this in just a little bit.

--

## Multistability

&gt; Things have more than one use, technology especially.

???

Think of a hammer. It can be a construction tool, a paperweight, or a weapon. Don't confuse this with *convergence*, for example with a phone now being a GPS, a camera, and so on, as these various technologies have converged into one. No, here we're talking about a technology that is built for one thing but has various (multiple) different possibly unintended functions. 

The Necker cube, for example. You can see it one way, then you can see it another, but the thing itself doesn't change. It's simply how you're perceiving it and its existence in the world. 

--

## Transparency

&gt; When technology fades from "view."

???

If you're thinking of Heidegger and recall this from your philosophy of technology days, bravo!  the hammer is a tool but becomes something else entirely when it breaks. When it's functioning, though, a sense of embodiment arises and the hammer and hammer user become one. Like an air conditioner: you don't really think much about it until it doesn't work. If you're a gamer, think of this as the controller: eventually you stop feeling that technology as something opaque between you and the screen. 

This is somewhat related to another topic: embodiment. That is, through our habits and repeated use of a technology, the line between subject and object begins to blur. Think of a master painter and a brush, or a virtuoso violinist and their instrument; they very nearly become *one*.

And this leads us to the fun stuff: technic relations.

---
class: secondary-river
background-image: url("assets/ua_horiz_rgb_4.svg")
background-size: 20%
background-position: 95% 95%

# Technic Relations

(icon)

???

The real goal of all this--and, hopefully, why you're here--is to discuss just how we relate to the world through, because of, and maybe even sometimes *in spite of* technologies.

So I'm going to run through the original four really quick. These were outlined in Ihde's "Technology and the Lifeworld." I'll then very briefly point out the newer relations that have come about since these as technology has advanced.

---
class: brand-blue

# Embodiment

.pull-left[


]

.pull-right[


]

???

...


---
class: brand-blue

# Hermenutic

.pull-left[


]

.pull-right[


]

???

...




---
class: brand-blue

# Alterity

.pull-left[


]

.pull-right[


]

???

...




---
class: brand-blue

# Background

.pull-left[


]

.pull-right[


]

???

The air conditioner we talked about. 

---
class: brand-red

# The Next Generation

## Fusion

&gt; (I / Technology) -&gt; World

???

Here we start getting into more complex relations that you can imagine being used in cutting-edge or future online/virtual learning environments. Hopefully you're beginning to see where I'm going with all this.

First, fusion. Here we're talking about everything from IUDs to pacemakers, from implanted RFID chips to cochlear implants. In this case, there is no physical separation of the self and the technology. In fact, removing one of them from the equation breaks the entire thing down. A pacemaker without a user has no impact, and a user without a pacermaker is... well. You get the point. The person and the technology are literally **fused** insofar as experiencing the world is concerned.

--

## Immersion

&gt; I &lt;-&gt; Technology/World

???

This is reflexive technology. A "classic" example of this is a "smart mirror" you could find at a doctor's office. You look in the mirror but there's also a camera behind it that, using facial recognition, connects to your medical record and displays your vital statistics, information about your lifestyle, or even something like that at home that displays your daily schedule or mean plan for the day. Perhaps, in the case of the doctor's office, it will use algorithmic software to show you what you'll look like in five, ten, fifteen years if you continue your current health trends. Whatever the case may be. So you experience the world that's enmeshed with the technology, and the technology, being reflexive, reacts to you as much as you react to it. Hence this kind of bidirectionality. (Example from "Verbeek's theory of technological mediation" in FutureLearn.) 

--

## Augmentation

&gt; (I-Technology) -&gt; World -&gt; (Technology-World)

???

Told you we're getting complex! I'm sure you've used some sort of augmented reality application or tool, from Pokemon Go to maybe a HoloLens. In this case, a second layer of reality is overlayed on the one you're experiencing, and both you *and the tool* react to that. This is often called a "bifurcated" representation, as you're now seeing two different aspects of the world simultaneously.

Hopefully, you're beginning to think about just how this framework is starting to make sense when it comes to your online learning toolbox. I want to really start digging into that now, but first, time for a little thought experiment. I want you to imagine a typical online student, however they may look.

---
class: secondary-silver
background-image: url("assets/ua_horiz_rgb_black_4.svg")
background-size: 20%
background-position: 95% 95%

# Thought experiment

(icon)

???

Do you have it in your mind? Picture everything. The chair, the desk, the laptop or PC, the ambient sounds, the temperature, the lighting. Now picture what kind of LMS is coming through the screen. Is it responsive? Think about the PDF the student is reading on the screen: is it OCR friendly? 

Think about all these things and start categorizing them into the different relations: the mouse and keyboard are quote "part of" the student, so the embodiment relation is occurring. The way the course is designed is unfamiliar, so there's some breakdown in the hermeutic relation as the student tries to interpret what's presented. Perhaps the room is too cold or there's the hum of other machines nearby, so the background relation is impacting the student's ability to concentrate.  

And so on.

And what about when the student is in a synchronous online class, like via Zoom?

Zoombie?

---









































&lt;!-- Ending slide below --&gt;
---
class: arizona-blue
background-image: url(assets/ua_horiz_rgb_4.svg)
background-size: 260px
background-position: 5% 95%

# Thank you!

Contact info:


.content-box-bloom[You can find references and readings on the [MAVRX Lab's event page](https://mavrxlab.org/event/ac21/)!]

.pull-right[.pull-down[

ryanstraight@arizona.edu

&lt;br&gt;&lt;br&gt;&lt;br&gt;

]]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="assets/remark-zoom.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
